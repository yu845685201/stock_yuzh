"""
æ•°æ®åŒæ­¥ç®¡ç†å™¨
"""

import time
from typing import List, Dict, Any, Optional
from datetime import date, datetime, timedelta
from ..config import ConfigManager
from ..data_sources import PytdxSource, BaostockSource
from ..database import DatabaseConnection, Stock, DailyData
from .csv_writer import CsvWriter
from .fundamentals_manager import FundamentalsManager


class SyncManager:
    """æ•°æ®åŒæ­¥ç®¡ç†å™¨"""

    def __init__(self, config_manager: ConfigManager = None):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨

        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
        """
        self.config_manager = config_manager or ConfigManager()
        self.db_conn = DatabaseConnection(self.config_manager)
        self.csv_writer = CsvWriter(self.config_manager)

        # åˆå§‹åŒ–æ•°æ®æº
        self.pytdx_source = None
        self.baostock_source = None

        self._init_data_sources()

    def _init_data_sources(self) -> None:
        """åˆå§‹åŒ–æ•°æ®æº"""
        # åˆå§‹åŒ–Pytdxæ•°æ®æº
        if self.config_manager.get('data_sources.pytdx.enabled', True):
            pytdx_config = {
                'vipdoc_path': self.config_manager.get('data_sources.pytdx.vipdoc_path'),
                'data_path': self.config_manager.get_data_paths().get('csv')
            }
            self.pytdx_source = PytdxSource(pytdx_config)

        # åˆå§‹åŒ–Baostockæ•°æ®æº
        if self.config_manager.get('data_sources.baostock.enabled', True):
            baostock_config = {
                'data_path': self.config_manager.get_data_paths().get('csv')
            }
            self.baostock_source = BaostockSource(baostock_config)

        # åˆå§‹åŒ–åŸºæœ¬é¢æ•°æ®ç®¡ç†å™¨
        self.fundamentals_manager = FundamentalsManager(self.config_manager)

    def sync_all(self, save_to_csv: bool = True, save_to_db: bool = True) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰€æœ‰æ•°æ® - åŒ…å«5åˆ†é’ŸKçº¿æ•°æ®

        Args:
            save_to_csv: æ˜¯å¦ä¿å­˜åˆ°CSVæ–‡ä»¶
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        result = {
            'start_time': datetime.now(),
            'success': False,
            'stocks_count': 0,
            'daily_data_count': 0,
            'min5_data_count': 0,
            'errors': []
        }

        try:
            # 1. åŒæ­¥è‚¡ç¥¨åˆ—è¡¨
            stocks = self.sync_stocks(save_to_csv, save_to_db)
            result['stocks_count'] = len(stocks)

            # 2. åŒæ­¥æ—¥Kçº¿æ•°æ®
            daily_count = self.sync_daily_data(save_to_csv, save_to_db)
            result['daily_data_count'] = daily_count

            # 3. åŒæ­¥5åˆ†é’ŸKçº¿æ•°æ®
            min5_count = self.sync_5min_data(save_to_csv, save_to_db)
            result['min5_data_count'] = min5_count

            result['success'] = True
        except Exception as e:
            result['errors'].append(str(e))
            print(f"åŒæ­¥æ•°æ®å¤±è´¥: {e}")

        result['end_time'] = datetime.now()
        result['duration'] = (result['end_time'] - result['start_time']).total_seconds()

        return result

    def sync_stocks(self, save_to_csv: bool = True, save_to_db: bool = True) -> List[Dict[str, Any]]:
        """åŒæ­¥è‚¡ç¥¨åˆ—è¡¨ - ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ä½¿ç”¨çº¯baostockæ–¹æ¡ˆ"""
        all_stocks = []

        # ä»Baostockè·å–è‚¡ç¥¨åˆ—è¡¨
        if self.baostock_source:
            if self.baostock_source.connect():
                stocks = self.baostock_source.get_stock_list()
                all_stocks.extend(stocks)
                self.baostock_source.disconnect()

        # å»é‡ - ä¿®å¤å­—æ®µå¼•ç”¨é”™è¯¯ï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„å»é‡é€»è¾‘
        unique_stocks = {}
        for stock in all_stocks:
            code = stock.get('stock_code')
            ts_code = stock.get('ts_code')
            # ä¼˜å…ˆä½¿ç”¨ts_codeä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œstock_codeä½œä¸ºå¤‡é€‰
            unique_key = ts_code if ts_code else code
            if unique_key and unique_key not in unique_stocks:
                unique_stocks[unique_key] = stock
            else:
                print(f"âš ï¸  è·³è¿‡é‡å¤è‚¡ç¥¨: {unique_key}")

        stocks_list = list(unique_stocks.values())

        # ä¿å­˜æ•°æ®
        if save_to_csv:
            self.csv_writer.write_stocks(stocks_list)

        if save_to_db:
            self._save_stocks_to_db(stocks_list)

        print(f"åŒæ­¥è‚¡ç¥¨åˆ—è¡¨å®Œæˆï¼Œå…± {len(stocks_list)} åªè‚¡ç¥¨")
        return stocks_list

    def sync_daily_data(
        self,
        save_to_csv: bool = True,
        save_to_db: bool = True,
        start_date: date = None,
        end_date: date = None,
        codes: List[str] = None
    ) -> int:
        """
        åŒæ­¥æ—¥Kçº¿æ•°æ® - ä¸¥æ ¼æŒ‰ç…§åŠŸèƒ½è¦æ±‚ç›´æ¥åŠ è½½é€šè¾¾ä¿¡æ—¥Kçº¿æ•°æ®

        å®ç°é€»è¾‘ï¼š
        1. åŠ è½½{é€šè¾¾ä¿¡æ•°æ®æ ¹ç›®å½•}/vipdoc/{market}/lday/*.dayæ–‡ä»¶ï¼Œæ–‡ä»¶åæ˜¯è‚¡ç¥¨çš„ä¸åŒ…å«"."çš„tsç¼–ç 
        2. è¿‡æ»¤å‡ºæ—¶é—´èŒƒå›´å†…çš„æ—¥kçº¿æ•°æ®
        3. æ•°æ®ç»„è£…æˆè¡¨æ ¼ç»“æ„ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
        4. åŸºäºç»„è£…åçš„æ•°æ®ç”Ÿæˆcsvæ–‡ä»¶ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆä¸€ä¸ªcsvæ–‡ä»¶
        5. å°†ç»„è£…åçš„æ•°æ®å†™å…¥æ•°æ®è¡¨his_kline_dayï¼Œä½¿ç”¨ts_code+trade_dateåˆ¤æ–­insert/update

        Args:
            save_to_csv: æ˜¯å¦ä¿å­˜åˆ°CSVæ–‡ä»¶
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2020-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰.dayæ–‡ä»¶

        Returns:
            åŒæ­¥çš„æ•°æ®æ¡æ•°
        """
        # ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ï¼šæ—¥æœŸèŒƒå›´ä»2020-01-01å¼€å§‹
        if not start_date:
            start_date = date(2020, 1, 1)
        if not end_date:
            end_date = date.today()

        print(f"å¼€å§‹åŒæ­¥æ—¥Kçº¿æ•°æ®: {start_date} è‡³ {end_date}")

        # 1. æ‰¹é‡æ‰«ææ‰€æœ‰.dayæ–‡ä»¶ï¼Œè·å–è‚¡ç¥¨åˆ—è¡¨å’Œæ—¥Kçº¿æ•°æ®
        all_daily_data = []
        processed_files = 0

        try:
            if self.pytdx_source and self.pytdx_source.connect():
                # æ‰¹é‡æ‰«ææ‰€æœ‰å¸‚åœºçš„.dayæ–‡ä»¶
                all_daily_data = self._scan_all_day_files(start_date, end_date, codes)
                processed_files = len(set(data['ts_code'] for data in all_daily_data))
                print(f"æˆåŠŸæ‰«æ {processed_files} åªè‚¡ç¥¨çš„æ—¥Kçº¿æ•°æ®ï¼Œå…± {len(all_daily_data)} æ¡è®°å½•")
            else:
                print("âŒ æ— æ³•è¿æ¥åˆ°Pytdxæ•°æ®æº")
                return 0

        except Exception as e:
            print(f"âŒ æ‰«æ.dayæ–‡ä»¶å¤±è´¥: {e}")
            return 0

        if not all_daily_data:
            print("âš ï¸  æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ—¥Kçº¿æ•°æ®")
            return 0

        # 3. æ•°æ®ç»„è£… - åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
        enriched_data = self._assemble_daily_data_with_fundamentals(all_daily_data)
        print(f"æ•°æ®ç»„è£…å®Œæˆï¼Œå…± {len(enriched_data)} æ¡è®°å½•")

        # 5. æ•°æ®æŒä¹…åŒ–
        total_count = 0
        if enriched_data:
            batch_size = self.config_manager.get('sync.batch_size', 5000)

            for i in range(0, len(enriched_data), batch_size):
                batch = enriched_data[i:i+batch_size]

                try:
                    if save_to_csv:
                        self.csv_writer.write_his_kline_day(batch)
                    if save_to_db:
                        self._save_daily_data_to_db(batch)

                    total_count += len(batch)
                    print(f"å·²å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} æ¡è®°å½•")

                except Exception as e:
                    print(f"âŒ å¤„ç†æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")

        print(f"âœ… æ—¥Kçº¿æ•°æ®åŒæ­¥å®Œæˆï¼Œå…±å¤„ç† {total_count} æ¡æ•°æ®ï¼Œæ¶‰åŠ {processed_files} åªè‚¡ç¥¨")
        return total_count

    def _process_daily_data_according_to_requirements(self, daily_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æŒ‰ç…§äº§å“è¦æ±‚å¤„ç†æ—¥Kçº¿æ•°æ® - ä¸¥æ ¼æŒ‰ç…§6æ­¥éª¤20å­—æ®µè¦æ±‚

        Args:
            daily_data: åŸå§‹æ—¥Kçº¿æ•°æ®åˆ—è¡¨

        Returns:
            å¤„ç†åçš„æ—¥Kçº¿æ•°æ®åˆ—è¡¨
        """
        if not daily_data:
            return []

        processed_data = []

        # æŒ‰æ—¥æœŸæ’åºä»¥è®¡ç®—æ˜¨æ—¥æ”¶ç›˜ä»·
        daily_data.sort(key=lambda x: x.get('trade_date'))

        for i, data in enumerate(daily_data):
            try:
                # æ­¥éª¤3ï¼šæ•°æ®è¡¥å……
                # è®¡ç®—precloseï¼ˆæ˜¨æ—¥æ”¶ç›˜ä»·ï¼‰
                preclose = None
                if i > 0:
                    preclose = daily_data[i-1].get('close')

                # åˆ¤æ–­is_stï¼ˆæ˜¯å¦STè‚¡ï¼‰
                stock_name = data.get('stock_name', '')
                is_st = 'ST' in stock_name.upper()

                # pe_ttm, pb_rate, ps_ttm, pcf_ttm ç•™ç©ºï¼ˆæŒ‰ç…§è¦æ±‚ï¼‰
                processed_record = {
                    'ts_code': data.get('ts_code'),
                    'stock_code': data.get('stock_code'),
                    'stock_name': stock_name,
                    'trade_date': data.get('trade_date'),
                    'open': data.get('open'),
                    'high': data.get('high'),
                    'low': data.get('low'),
                    'close': data.get('close'),
                    'preclose': preclose,  # è®¡ç®—æ‰€å¾—
                    'volume': data.get('volume'),
                    'amount': data.get('amount'),
                    'trade_status': data.get('trade_status', 1),  # é»˜è®¤æ­£å¸¸äº¤æ˜“
                    'is_st': is_st,  # åˆ¤æ–­æ‰€å¾—
                    'adjust_flag': data.get('adjust_flag', 3),  # é»˜è®¤ä¸å¤æƒ
                    'change_rate': data.get('change_rate'),
                    'turnover_rate': data.get('turnover_rate'),
                    'pe_ttm': None,  # æŒ‰è¦æ±‚ç•™ç©º
                    'pb_rate': None,  # æŒ‰è¦æ±‚ç•™ç©º
                    'ps_ttm': None,  # æŒ‰è¦æ±‚ç•™ç©º
                    'pcf_ttm': None  # æŒ‰è¦æ±‚ç•™ç©º
                }

                processed_data.append(processed_record)

            except Exception as e:
                print(f"å¤„ç†æ—¥Kçº¿æ•°æ®å¤±è´¥: {data}, é”™è¯¯: {e}")
                continue

        return processed_data

    
    def _scan_all_day_files(self, start_date: date, end_date: date, codes: List[str] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰«ææ‰€æœ‰.dayæ–‡ä»¶ï¼Œè·å–æ—¥Kçº¿æ•°æ® - ä½¿ç”¨é€šç”¨æ‰«ææ–¹æ³•

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            codes: æŒ‡å®šçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰

        Returns:
            æ—¥Kçº¿æ•°æ®åˆ—è¡¨
        """
        return self._scan_all_files(start_date, end_date, codes, 'day')

    
    def _assemble_daily_data_with_fundamentals(self, daily_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ•°æ®ç»„è£… - åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL

        Args:
            daily_data: æ—¥Kçº¿æ•°æ®åˆ—è¡¨

        Returns:
            ç»„è£…åçš„æ—¥Kçº¿æ•°æ®åˆ—è¡¨
        """
        enriched_data = []

        for record in daily_data:
            enriched_record = record.copy()
            # åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
            enriched_record['turnover_rate'] = None
            enriched_data.append(enriched_record)

        # ä¿®å¤ï¼šåŸºäºts_codeå’Œtrade_dateå»é‡ï¼Œä¿ç•™æœ€åä¸€æ¡è®°å½•
        import pandas as pd
        df = pd.DataFrame(enriched_data)
        if not df.empty:
            df_deduped = df.drop_duplicates(subset=['ts_code', 'trade_date'], keep='last')
            enriched_data = df_deduped.to_dict('records')

        return enriched_data

    def _post_process_daily_data(self, daily_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åå¤„ç†æ—¥Kçº¿æ•°æ® - è®¡ç®—æ¶¨è·Œå¹…

        Args:
            daily_data: æ—¥Kçº¿æ•°æ®åˆ—è¡¨

        Returns:
            å¤„ç†åçš„æ—¥Kçº¿æ•°æ®åˆ—è¡¨
        """
        if len(daily_data) <= 1:
            return daily_data

        # æŒ‰æ—¥æœŸæ’åº
        daily_data.sort(key=lambda x: x['trade_date'])

        # è®¡ç®—æ¶¨è·Œå¹…å’Œè®¾ç½®æ˜¨æ—¥æ”¶ç›˜ä»·
        for i in range(len(daily_data)):
            if i > 0:
                # è®¾ç½®æ˜¨æ—¥æ”¶ç›˜ä»·
                daily_data[i]['preclose'] = daily_data[i-1]['close']
                # è®¡ç®—æ¶¨è·Œå¹…
                if daily_data[i]['preclose'] and daily_data[i]['close']:
                    try:
                        from ..utils.data_transformer import DataTransformer
                        daily_data[i]['change_rate'] = DataTransformer.calculate_change_rate(
                            daily_data[i]['close'], daily_data[i]['preclose']
                        )
                    except Exception as e:
                        print(f"âš ï¸  è®¡ç®—æ¶¨è·Œå¹…å¤±è´¥ {daily_data[i]['ts_code']}: {e}")
                        daily_data[i]['change_rate'] = None

        return daily_data

    def _scan_all_files(self, start_date: date, end_date: date,
                       codes: List[str] = None,
                       file_type: str = 'day') -> List[Dict[str, Any]]:
        """
        é€šç”¨æ–‡ä»¶æ‰«ææ–¹æ³• - æ”¯æŒæ—¥Kçº¿å’Œ5åˆ†é’ŸKçº¿æ–‡ä»¶

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            codes: æŒ‡å®šçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
            file_type: æ–‡ä»¶ç±»å‹ ('day' æˆ– '5min')

        Returns:
            Kçº¿æ•°æ®åˆ—è¡¨
        """
        import os
        from ..utils.data_transformer import DataTransformer

        # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®å‚æ•°
        if file_type == 'day':
            subdir = 'lday'
            ext = '.day'
            parse_func = DataTransformer.parse_day_file_data
            record_size = 32
            time_field = None  # æ—¥Kçº¿æ²¡æœ‰æ—¶é—´å­—æ®µ
        elif file_type == '5min':
            subdir = 'fzline'
            ext = '.lc5'
            parse_func = DataTransformer.parse_minute_file_data
            record_size = 28
            time_field = 'trade_time'
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

        all_data = []
        vipdoc_path = self.pytdx_source.vipdoc_path
        markets = ['bj', 'sh', 'sz']
        processed_files = 0

        for market in markets:
            market_path = os.path.join(vipdoc_path, market, subdir)
            if not os.path.exists(market_path):
                print(f"âš ï¸  å¸‚åœºç›®å½•ä¸å­˜åœ¨: {market_path}")
                continue

            try:
                files = [f for f in os.listdir(market_path) if f.endswith(ext)]
                print(f"ğŸ“ æ‰«æ {market} å¸‚åœº: æ‰¾åˆ° {len(files)} ä¸ª{ext}æ–‡ä»¶")

                for filename in files:
                    if not filename.startswith(market):
                        continue

                    stock_code = filename[2:-len(ext)]  # å»æ‰marketå‰ç¼€å’Œæ‰©å±•å

                    # å¦‚æœæŒ‡å®šäº†codesï¼Œåªå¤„ç†æŒ‡å®šçš„è‚¡ç¥¨
                    if codes and stock_code not in codes:
                        continue

                    filepath = os.path.join(market_path, filename)
                    ts_code = f"{market}.{stock_code}"

                    try:
                        # è¯»å–æ–‡ä»¶æ•°æ®
                        with open(filepath, 'rb') as f:
                            file_data = []
                            # æ¯æ¡è®°å½•çš„å­—èŠ‚æ•°
                            while True:
                                data = f.read(record_size)
                                if not data:
                                    break

                                # è§£ææ–‡ä»¶æ•°æ®
                                parsed_data = parse_func(data, stock_code, market)
                                if parsed_data is None:
                                    continue

                                trade_date = parsed_data['trade_date']

                                # è¿‡æ»¤æ—¥æœŸèŒƒå›´
                                if start_date and trade_date < start_date:
                                    continue
                                if end_date and trade_date > end_date:
                                    continue

                                # æ„å»ºKçº¿è®°å½•
                                if file_type == 'day':
                                    record = {
                                        'ts_code': ts_code,
                                        'stock_code': stock_code,
                                        'stock_name': None,  # åç»­ä»æ•°æ®åº“æŸ¥è¯¢
                                        'trade_date': trade_date,
                                        'open': parsed_data['open'],
                                        'high': parsed_data['high'],
                                        'low': parsed_data['low'],
                                        'close': parsed_data['close'],
                                        'preclose': parsed_data.get('preclose'),  # ä»æ–‡ä»¶è§£æ
                                        'volume': parsed_data['volume'],
                                        'amount': parsed_data['amount'],
                                        'trade_status': None,
                                        'is_st': None,
                                        'adjust_flag': 3,  # é»˜è®¤ä¸å¤æƒ
                                        'change_rate': None,  # åç»­è®¡ç®—
                                        'turnover_rate': None,  # åç»­è®¡ç®—
                                        'pe_ttm': None,
                                        'pb_rate': None,
                                        'ps_ttm': None,
                                        'pcf_ttm': None
                                    }
                                else:  # 5min
                                    record = {
                                        'ts_code': ts_code,
                                        'stock_code': stock_code,
                                        'stock_name': None,  # åç»­ä»æ•°æ®åº“æŸ¥è¯¢
                                        'trade_date': trade_date,
                                        'trade_time': parsed_data['trade_time'],
                                        'open': parsed_data['open'],
                                        'high': parsed_data['high'],
                                        'low': parsed_data['low'],
                                        'close': parsed_data['close'],
                                        'preclose': None,  # åç»­è®¡ç®—
                                        'volume': parsed_data['volume'],
                                        'amount': parsed_data['amount'],
                                        'adjust_flag': 3,
                                        'change_rate': None,  # åç»­è®¡ç®—
                                        'turnover_rate': None  # åç»­è®¡ç®—
                                    }

                                file_data.append(record)

                            # åå¤„ç†ï¼šè®¡ç®—æ¶¨è·Œå¹…ï¼ˆä»…å¯¹æ—¥Kçº¿ï¼‰
                            if file_type == 'day':
                                file_data = self._post_process_daily_data(file_data)
                            else:  # 5min
                                file_data = self._post_process_5min_data(file_data)

                            all_data.extend(file_data)
                            processed_files += 1

                    except Exception as e:
                        # ç»Ÿä¸€çš„æ–‡ä»¶è¯»å–é”™è¯¯å¤„ç†
                        print(f"âŒ è¯»å–æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
                        continue

            except Exception as e:
                # ç»Ÿä¸€çš„ç›®å½•æ‰«æé”™è¯¯å¤„ç†
                print(f"âŒ æ‰«æå¸‚åœºç›®å½• {market_path} å¤±è´¥: {e}")
                continue

        file_type_name = "æ—¥Kçº¿" if file_type == 'day' else "5åˆ†é’ŸKçº¿"
        print(f"âœ… æˆåŠŸæ‰«æ {processed_files} åªè‚¡ç¥¨çš„{file_type_name}æ•°æ®ï¼Œå…± {len(all_data)} æ¡è®°å½•")
        return all_data

    def _scan_all_5min_files(self, start_date: date, end_date: date,
                             codes: List[str] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰«ææ‰€æœ‰.lc5æ–‡ä»¶ï¼Œè·å–5åˆ†é’ŸKçº¿æ•°æ® - ä½¿ç”¨é€šç”¨æ‰«ææ–¹æ³•

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            codes: æŒ‡å®šçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            5åˆ†é’ŸKçº¿æ•°æ®åˆ—è¡¨
        """
        return self._scan_all_files(start_date, end_date, codes, '5min')

    def _post_process_5min_data(self, min5_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åå¤„ç†5åˆ†é’ŸKçº¿æ•°æ® - è®¡ç®—æ¶¨è·Œå¹…ï¼ˆåŸºäºæ˜¨æ—¥æ”¶ç›˜ä»·ï¼‰"""
        if not min5_data:
            return min5_data

        # æŒ‰è‚¡ç¥¨å’Œæ—¥æœŸæ—¶é—´æ’åº
        min5_data.sort(key=lambda x: (x['ts_code'], x['trade_date'], x['trade_time']))

        # è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ˜¨æ—¥æ”¶ç›˜ä»·æ˜ å°„
        stock_codes = list(set(data['ts_code'] for data in min5_data))
        preclose_map = self._get_yesterday_preclose_map(stock_codes)

        # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—æ¶¨è·Œå¹…
        for data in min5_data:
            ts_code = data['ts_code']
            trade_date = data['trade_date']

            # è·å–æ˜¨æ—¥æ”¶ç›˜ä»·
            yesterday_preclose = preclose_map.get(ts_code, {}).get(trade_date)

            if yesterday_preclose and data['close']:
                try:
                    from ..utils.data_transformer import DataTransformer
                    data['change_rate'] = DataTransformer.calculate_change_rate(
                        data['close'], yesterday_preclose
                    )
                    data['preclose'] = yesterday_preclose
                except Exception as e:
                    print(f"âš ï¸  è®¡ç®—æ¶¨è·Œå¹…å¤±è´¥ {ts_code}: {e}")
                    data['change_rate'] = None
                    data['preclose'] = yesterday_preclose
            else:
                data['change_rate'] = None
                data['preclose'] = yesterday_preclose

        return min5_data

    def _get_yesterday_preclose_map(self, ts_codes: List[str]) -> Dict[str, Dict[date, float]]:
        """
        è·å–è‚¡ç¥¨çš„æ˜¨æ—¥æ”¶ç›˜ä»·æ˜ å°„è¡¨

        Args:
            ts_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            Dict[ts_code, Dict[trade_date, preclose]]: è‚¡ç¥¨ä»£ç ->äº¤æ˜“æ—¥æœŸ->æ˜¨æ—¥æ”¶ç›˜ä»·
        """
        if not ts_codes:
            return {}

        preclose_map = {}

        for ts_code in ts_codes:
            try:
                # æŸ¥è¯¢è¯¥è‚¡ç¥¨çš„æ—¥Kçº¿æ•°æ®ï¼Œè·å–æ˜¨æ—¥æ”¶ç›˜ä»·
                daily_data = self.db_conn.fetch_all("""
                    SELECT trade_date, close
                    FROM his_kline_day
                    WHERE ts_code = %s
                    ORDER BY trade_date DESC
                    LIMIT 100
                """, (ts_code,))

                if daily_data:
                    # æ„å»ºæ—¥æœŸ->æ˜¨æ—¥æ”¶ç›˜ä»·çš„æ˜ å°„
                    date_to_preclose = {}
                    for i, record in enumerate(daily_data):
                        current_date = record['trade_date']
                        current_close = record['close']

                        # æ˜¨æ—¥æ”¶ç›˜ä»·æ˜¯ä¸‹ä¸€å¤©çš„preclose
                        if i > 0:
                            previous_date = daily_data[i-1]['trade_date']
                            date_to_preclose[previous_date] = current_close

                    preclose_map[ts_code] = date_to_preclose

            except Exception as e:
                print(f"âš ï¸  è·å–è‚¡ç¥¨ {ts_code} çš„æ˜¨æ—¥æ”¶ç›˜ä»·å¤±è´¥: {e}")
                preclose_map[ts_code] = {}

        return preclose_map

    def _assemble_5min_data_with_fundamentals(self, min5_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ•°æ®ç»„è£… - 5åˆ†é’Ÿç‰ˆæœ¬ï¼ŒåŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL"""
        enriched_data = []

        for record in min5_data:
            enriched_record = record.copy()
            # åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
            enriched_record['turnover_rate'] = None
            enriched_data.append(enriched_record)

        return enriched_data

    
    def _get_all_stock_info(self, codes: List[str] = None, filter_delisted: bool = True) -> List[Dict[str, Any]]:
        """
        ä»base_stock_infoè¡¨è·å–è‚¡ç¥¨ä¿¡æ¯

        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            filter_delisted: æ˜¯å¦è¿‡æ»¤é€€å¸‚è‚¡ç¥¨ï¼Œé»˜è®¤True

        Returns:
            è‚¡ç¥¨ä¿¡æ¯åˆ—è¡¨
        """
        try:
            if codes:
                # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
                code_list = "', '".join(codes)
                list_status_filter = "AND list_status = 'L'" if filter_delisted else ""
                query = f"""
                SELECT ts_code, stock_code, stock_name, list_status
                FROM base_stock_info
                WHERE stock_code IN ('{code_list}') {list_status_filter}
                ORDER BY ts_code
                """
                print(f"æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨ä»£ç : {codes} {'(ä»…ä¸Šå¸‚è‚¡ç¥¨)' if filter_delisted else '(åŒ…å«é€€å¸‚è‚¡ç¥¨)'}")
            else:
                # æŸ¥è¯¢å…¨é‡æ•°æ®
                list_status_filter = "WHERE list_status = 'L'" if filter_delisted else ""
                query = f"""
                SELECT ts_code, stock_code, stock_name, list_status
                FROM base_stock_info
                {list_status_filter}
                ORDER BY ts_code
                """
                print(f"æŸ¥è¯¢å…¨é‡è‚¡ç¥¨ä¿¡æ¯ {'(ä»…ä¸Šå¸‚è‚¡ç¥¨)' if filter_delisted else '(åŒ…å«é€€å¸‚è‚¡ç¥¨)'}")

            stocks = self.db_conn.fetch_all(query)

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            if filter_delisted:
                print(f"âœ… è¿‡æ»¤é€€å¸‚è‚¡ç¥¨ï¼Œè·å–åˆ° {len(stocks)} åªä¸Šå¸‚è‚¡ç¥¨")
            else:
                listed_count = len([s for s in stocks if s.get('list_status') == 'L'])
                delisted_count = len([s for s in stocks if s.get('list_status') != 'L'])
                print(f"ğŸ“Š è‚¡ç¥¨åˆ†å¸ƒ: ä¸Šå¸‚ {listed_count} åª, é€€å¸‚ {delisted_count} åª, æ€»è®¡ {len(stocks)} åª")

            return stocks
        except Exception as e:
            print(f"æŸ¥è¯¢base_stock_infoè¡¨å¤±è´¥: {e}")
            return []

    def sync_1min_data(
        self,
        save_to_csv: bool = True,
        save_to_db: bool = True,
        start_date: date = None,
        end_date: date = None,
        codes: List[str] = None
    ) -> int:
        """
        åŒæ­¥1åˆ†é’ŸKçº¿æ•°æ® - ä¸¥æ ¼æŒ‰ç…§äº§å“è®¾è®¡æ–‡æ¡£è¦æ±‚

        Args:
            save_to_csv: æ˜¯å¦ä¿å­˜åˆ°CSVæ–‡ä»¶
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º7å¤©å‰
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºNoneåˆ™åŒæ­¥æ‰€æœ‰è‚¡ç¥¨

        Returns:
            åŒæ­¥çš„æ•°æ®æ¡æ•°
        """
        if not start_date:
            start_date = date.today() - timedelta(days=7)
        if not end_date:
            end_date = date.today()

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        if not codes:
            stocks = self.sync_stocks(False, False)
            codes = [stock['stock_code'] for stock in stocks]

        total_count = 0
        batch_size = self.config_manager.get('sync.batch_size', 1000)  # 1åˆ†é’Ÿæ•°æ®é‡æ›´å¤§
        all_min1_data = []

        for i, code in enumerate(codes):
            try:
                # ä½¿ç”¨Pytdxè·å–1åˆ†é’ŸKçº¿æ•°æ®
                data = None
                if self.pytdx_source:
                    if self.pytdx_source.connect():
                        data = self.pytdx_source.get_minute_data(code, '1min', start_date, end_date)
                        self.pytdx_source.disconnect()

                if data:
                    # æå–è‚¡ç¥¨ts_codeé›†åˆï¼ŒæŸ¥è¯¢base_fundamentals_infoè¡¨
                    # ä»ç¬¬ä¸€æ¡è®°å½•è·å–ts_code
                    ts_code = data[0].get('ts_code') if data else None
                    if ts_code:
                        enriched_data = self._enrich_minute_data_with_fundamentals(data, ts_code)
                        all_min1_data.extend(enriched_data)

                    # æ‰¹é‡å¤„ç†
                    if len(all_min1_data) >= batch_size or i == len(codes) - 1:
                        if save_to_csv:
                            self.csv_writer.write_his_kline_1min(all_min1_data)
                        if save_to_db:
                            self._save_1min_data_to_db(all_min1_data)
                        total_count += len(all_min1_data)
                        print(f"å·²å¤„ç† {i+1}/{len(codes)} åªè‚¡ç¥¨ï¼ŒåŒæ­¥1åˆ†é’Ÿæ•°æ® {total_count} æ¡")
                        all_min1_data = []

            except Exception as e:
                print(f"åŒæ­¥è‚¡ç¥¨ {code} çš„1åˆ†é’ŸKçº¿æ•°æ®å¤±è´¥: {e}")

        print(f"åŒæ­¥1åˆ†é’ŸKçº¿æ•°æ®å®Œæˆï¼Œå…± {total_count} æ¡æ•°æ®")
        return total_count

    def _enrich_minute_data_with_fundamentals(self, minute_data: List[Dict[str, Any]], ts_code: str) -> List[Dict[str, Any]]:
        """
        ä¸ºåˆ†é’ŸKçº¿æ•°æ®æ·»åŠ åŸºç¡€ä¿¡æ¯ - åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL

        Args:
            minute_data: åˆ†é’ŸKçº¿æ•°æ®åˆ—è¡¨
            ts_code: tsä»£ç 

        Returns:
            ä¸°å¯Œåçš„åˆ†é’ŸKçº¿æ•°æ®åˆ—è¡¨
        """
        try:
            # ä»base_stock_infoè¡¨è·å–stock_name
            stock_query = """
            SELECT ts_code, stock_code, stock_name
            FROM base_stock_info
            WHERE ts_code = %s
            """
            stock_info = self.db_conn.fetch_one(stock_query, (ts_code,))

            # ä¸°å¯Œæ¯æ¡åˆ†é’ŸKçº¿æ•°æ®
            enriched_data = []
            for record in minute_data:
                enriched_record = record.copy()
                if stock_info:
                    enriched_record['stock_name'] = stock_info['stock_name']
                else:
                    enriched_record['stock_name'] = None

                # åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
                enriched_record['turnover_rate'] = None
                enriched_data.append(enriched_record)

            return enriched_data

        except Exception as e:
            print(f"ä¸°å¯Œåˆ†é’ŸKçº¿æ•°æ®åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
            return minute_data

    def _save_1min_data_to_db(self, min1_data: List[Dict[str, Any]]) -> None:
        """ä¿å­˜1åˆ†é’ŸKçº¿æ•°æ®åˆ°æ•°æ®åº“ - ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£è¦æ±‚ä½¿ç”¨ts_code+trade_date+trade_timeåˆ¤æ–­"""
        batch_size = self.config_manager.get('sync.batch_size', 2000)
        for i in range(0, len(min1_data), batch_size):
            batch = min1_data[i:i+batch_size]
            values = []
            for data in batch:
                values.append((
                    data.get('ts_code'),
                    data.get('stock_code'),
                    data.get('stock_name'),
                    data.get('trade_date'),
                    data.get('trade_time'),
                    data.get('open'),
                    data.get('high'),
                    data.get('low'),
                    data.get('close'),
                    data.get('preclose'),
                    data.get('volume'),
                    data.get('amount'),
                    data.get('adjust_flag', 3),
                    data.get('change_rate'),
                    data.get('turnover_rate')
                ))

            query = """
                INSERT INTO his_kline_1min (
                    ts_code, stock_code, stock_name, trade_date, trade_time,
                    open, high, low, close, preclose, volume, amount,
                    adjust_flag, change_rate, turnover_rate
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ts_code, trade_date, trade_time) DO UPDATE SET
                    stock_code = EXCLUDED.stock_code,
                    stock_name = EXCLUDED.stock_name,
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    preclose = EXCLUDED.preclose,
                    volume = EXCLUDED.volume,
                    amount = EXCLUDED.amount,
                    adjust_flag = EXCLUDED.adjust_flag,
                    change_rate = EXCLUDED.change_rate,
                    turnover_rate = EXCLUDED.turnover_rate,
                    update_time = CURRENT_TIMESTAMP
            """
            self.db_conn.execute_batch(query, values)

    def sync_5min_data(
        self,
        save_to_csv: bool = True,
        save_to_db: bool = True,
        start_date: date = None,
        end_date: date = None,
        codes: List[str] = None
    ) -> int:
        """
        åŒæ­¥5åˆ†é’ŸKçº¿æ•°æ® - å®ç”¨å¹³è¡¡ç‰ˆæœ¬ï¼Œå®Œå…¨æ— Baostockä¾èµ–

        ä¿æŒç°æœ‰æ¥å£ä¸å˜ï¼Œå†…éƒ¨å®ç°é‡‡ç”¨æ··åˆæ¨¡å¼ï¼š
        - å¦‚æœæœªæŒ‡å®šcodesï¼Œä½¿ç”¨æ‰¹é‡æ‰«ææ¨¡å¼ï¼ˆé«˜æ€§èƒ½ï¼‰
        - å¦‚æœæŒ‡å®šcodesï¼Œä½¿ç”¨é€è‚¡ç¥¨å¤„ç†æ¨¡å¼ï¼ˆå…¼å®¹æ€§ï¼‰
        - å®Œå…¨æ— Baostockä¾èµ–
        - æ”¯æŒéšæœºé€‰æ‹©10æ”¯è‚¡ç¥¨è¿›è¡Œæµ‹è¯•

        Args:
            save_to_csv: æ˜¯å¦ä¿å­˜åˆ°CSVæ–‡ä»¶
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2025-12-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰.lc5æ–‡ä»¶

        Returns:
            åŒæ­¥çš„æ•°æ®æ¡æ•°
        """
        # ä½¿ç”¨é…ç½®åŒ–çš„é»˜è®¤æ—¥æœŸèŒƒå›´
        if not start_date:
            default_start_str = self.config_manager.get('sync.5min_data.default_start_date', '2025-12-01')
            try:
                start_date = datetime.strptime(default_start_str, '%Y-%m-%d').date()
            except ValueError:
                start_date = date(2025, 12, 1)
        if not end_date:
            end_date = date.today()

        print(f"å¼€å§‹åŒæ­¥5åˆ†é’ŸKçº¿æ•°æ®: {start_date} è‡³ {end_date}")

        # æ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼
        if not codes:
            # æ‰¹é‡æ‰«ææ¨¡å¼ï¼šé«˜æ€§èƒ½å¤„ç†æ‰€æœ‰æ•°æ®
            return self._sync_5min_batch_mode(save_to_csv, save_to_db, start_date, end_date)
        else:
            # å…¼å®¹æ¨¡å¼ï¼šå¤„ç†æŒ‡å®šè‚¡ç¥¨
            return self._sync_5min_compatibility_mode(save_to_csv, save_to_db,
                                                     start_date, end_date, codes)

    def _sync_5min_batch_mode(self, save_to_csv: bool, save_to_db: bool,
                             start_date: date, end_date: date) -> int:
        """æ‰¹é‡æ‰«ææ¨¡å¼ - å‚è€ƒæ—¥Kçº¿æ¶æ„"""
        print("ğŸš€ ä½¿ç”¨æ‰¹é‡æ‰«ææ¨¡å¼")

        # 1. æ‰¹é‡æ‰«ææ‰€æœ‰.lc5æ–‡ä»¶
        all_5min_data = []
        try:
            if self.pytdx_source and self.pytdx_source.connect():
                all_5min_data = self._scan_all_5min_files(start_date, end_date)
                self.pytdx_source.disconnect()
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ‰«æå¤±è´¥: {e}")
            return 0

        if not all_5min_data:
            print("âš ï¸  æœªæ‰¾åˆ°5åˆ†é’ŸKçº¿æ•°æ®")
            return 0

        # 2. æ‰¹é‡å¤„ç†æ•°æ®ï¼ˆå¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„æ•°æ®ï¼‰
        print(f"âœ… æ‰¾åˆ° {len(set(data['ts_code'] for data in all_5min_data))} æ”¯è‚¡ç¥¨çš„5åˆ†é’ŸKçº¿æ•°æ®")
        return self._process_5min_data_batch(all_5min_data, save_to_csv, save_to_db)

    def _sync_5min_compatibility_mode(self, save_to_csv: bool, save_to_db: bool,
                                     start_date: date, end_date: date,
                                     codes: List[str]) -> int:
        """å…¼å®¹æ¨¡å¼ - å¤„ç†æŒ‡å®šè‚¡ç¥¨"""
        print(f"ğŸ”§ ä½¿ç”¨å…¼å®¹æ¨¡å¼å¤„ç† {len(codes)} æ”¯æŒ‡å®šè‚¡ç¥¨")

        # ä½¿ç”¨ç°æœ‰çš„é€è‚¡ç¥¨å¤„ç†é€»è¾‘ï¼Œä½†è‚¡ç¥¨è·å–ä¸ä¾èµ–Baostock
        total_count = 0
        batch_size = self.config_manager.get('sync.batch_size', 10000)
        all_5min_data = []

        for i, code in enumerate(codes):
            try:
                # ä½¿ç”¨Pytdxè·å–5åˆ†é’ŸKçº¿æ•°æ®
                data = None
                if self.pytdx_source and self.pytdx_source.connect():
                    data = self.pytdx_source.get_minute_data(code, '5min', start_date, end_date)
                    self.pytdx_source.disconnect()

                if data:
                    # æ‰¹é‡ç§¯ç´¯æ•°æ®
                    all_5min_data.extend(data)

                    # æ‰¹é‡å¤„ç†
                    if len(all_5min_data) >= batch_size or i == len(codes) - 1:
                        processed_count = self._process_5min_data_batch(
                            all_5min_data, save_to_csv, save_to_db
                        )
                        total_count += processed_count
                        all_5min_data = []
                        print(f"å·²å¤„ç† {i+1}/{len(codes)} åªè‚¡ç¥¨ï¼ŒåŒæ­¥æ•°æ® {total_count} æ¡")

            except Exception as e:
                print(f"åŒæ­¥è‚¡ç¥¨ {code} çš„5åˆ†é’ŸKçº¿æ•°æ®å¤±è´¥: {e}")

        return total_count

    def _process_5min_data_batch(self, min5_data: List[Dict[str, Any]],
                               save_to_csv: bool, save_to_db: bool) -> int:
        """æ‰¹é‡å¤„ç†5åˆ†é’Ÿæ•°æ® - ç»Ÿä¸€çš„æ•°æ®å¤„ç†é€»è¾‘"""
        if not min5_data:
            return 0

        # 2. æ•°æ®ç»„è£… - åŸºæœ¬é¢æ•°æ®å·²åˆ é™¤ï¼Œæ¢æ‰‹ç‡è®¾ä¸ºNULL
        enriched_data = self._assemble_5min_data_with_fundamentals(min5_data)
        enriched_data = self._post_process_5min_data(enriched_data)

        # 4. æ•°æ®æŒä¹…åŒ–
        try:
            if save_to_csv:
                self.csv_writer.write_his_kline_5min(enriched_data)
            if save_to_db:
                self._save_5min_data_to_db(enriched_data)

            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {len(enriched_data)} æ¡è®°å½•")
            return len(enriched_data)

        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return 0

    
    def _save_5min_data_to_db(self, min5_data: List[Dict[str, Any]]) -> None:
        """
        ä¿å­˜5åˆ†é’ŸKçº¿æ•°æ®åˆ°æ•°æ®åº“ - ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£è¦æ±‚ä½¿ç”¨ts_code+trade_date+trade_timeåˆ¤æ–­

        Args:
            min5_data: 5åˆ†é’ŸKçº¿æ•°æ®åˆ—è¡¨
        """
        if not min5_data:
            return

        # ä½¿ç”¨åˆç†çš„æ‰¹æ¬¡å¤§å°ï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½
        batch_size = self.config_manager.get('sync.batch_size', 5000)

        for i in range(0, len(min5_data), batch_size):
            batch = min5_data[i:i+batch_size]
            values = []

            for data in batch:
                # å¢åŠ å­—æ®µå…¼å®¹æ€§å¤„ç†ï¼Œæ”¯æŒä¸åŒçš„å­—æ®µå
                values.append((
                    data.get('ts_code'),
                    data.get('stock_code') or data.get('code'),
                    data.get('stock_name') or data.get('name'),
                    data.get('trade_date'),
                    data.get('trade_time'),
                    data.get('open'),
                    data.get('high'),
                    data.get('low'),
                    data.get('close'),
                    data.get('preclose'),
                    data.get('volume'),
                    data.get('amount'),
                    data.get('adjust_flag', 3),  # é»˜è®¤ä¸å¤æƒ
                    data.get('change_rate'),
                    data.get('turnover_rate')
                ))

            # ä¸¥æ ¼æŒ‰ç…§æ–‡æ¡£è¦æ±‚ä½¿ç”¨ts_code+trade_date+trade_timeä½œä¸ºå†²çªé”®
            query = """
                INSERT INTO his_kline_5min (
                    ts_code, stock_code, stock_name, trade_date, trade_time,
                    open, high, low, close, preclose, volume, amount, adjust_flag,
                    change_rate, turnover_rate
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ts_code, trade_date, trade_time) DO UPDATE SET
                    stock_code = EXCLUDED.stock_code,
                    stock_name = EXCLUDED.stock_name,
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    preclose = EXCLUDED.preclose,
                    volume = EXCLUDED.volume,
                    amount = EXCLUDED.amount,
                    adjust_flag = EXCLUDED.adjust_flag,
                    change_rate = EXCLUDED.change_rate,
                    turnover_rate = EXCLUDED.turnover_rate,
                    update_time = CURRENT_TIMESTAMP
            """
            self.db_conn.execute_batch(query, values)

    def _save_stocks_to_db(self, stocks: List[Dict[str, Any]]) -> None:
        """ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°æ•°æ®åº“ - ä¿®å¤è¡¨åå’Œå­—æ®µæ˜ å°„"""
        batch_size = self.config_manager.get('sync.batch_size', 1000)  # ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
        for i in range(0, len(stocks), batch_size):
            batch = stocks[i:i+batch_size]
            values = []
            for stock in batch:
                # ç›´æ¥ä»å­—å…¸è·å–æ•°æ®ï¼Œé¿å…æ¨¡å‹è½¬æ¢é—®é¢˜
                values.append((
                    stock.get('ts_code'),
                    stock.get('stock_code') or stock.get('code'),  # å…¼å®¹ä¸åŒå­—æ®µå
                    stock.get('stock_name') or stock.get('name'),
                    stock.get('cnspell'),
                    stock.get('market_code') or stock.get('market'),
                    stock.get('market_name'),
                    stock.get('exchange_code'),
                    stock.get('sector_code'),
                    stock.get('sector_name'),
                    stock.get('industry_code'),
                    stock.get('industry_name') or stock.get('industry'),
                    stock.get('list_status') or stock.get('status'),
                    stock.get('list_date'),
                    stock.get('delist_date')
                ))

            query = """
                INSERT INTO base_stock_info (
                    ts_code, stock_code, stock_name, cnspell, market_code, market_name,
                    exchange_code, sector_code, sector_name, industry_code, industry_name,
                    list_status, list_date, delist_date
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ts_code) DO UPDATE SET
                    ts_code = EXCLUDED.ts_code,
                    stock_name = EXCLUDED.stock_name,
                    cnspell = EXCLUDED.cnspell,
                    market_code = EXCLUDED.market_code,
                    market_name = EXCLUDED.market_name,
                    exchange_code = EXCLUDED.exchange_code,
                    sector_code = EXCLUDED.sector_code,
                    sector_name = EXCLUDED.sector_name,
                    industry_code = EXCLUDED.industry_code,
                    industry_name = EXCLUDED.industry_name,
                    list_status = EXCLUDED.list_status,
                    list_date = EXCLUDED.list_date,
                    delist_date = EXCLUDED.delist_date,
                    update_time = CURRENT_TIMESTAMP
            """
            self.db_conn.execute_batch(query, values)

    def _save_daily_data_to_db(self, daily_data: List[Dict[str, Any]]) -> None:
        """ä¿å­˜æ—¥Kçº¿æ•°æ®åˆ°æ•°æ®åº“ - ä¿®å¤è¡¨åå’Œå­—æ®µæ˜ å°„"""
        batch_size = self.config_manager.get('sync.batch_size', 5000)  # ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
        for i in range(0, len(daily_data), batch_size):
            batch = daily_data[i:i+batch_size]
            values = []
            for data in batch:
                # ç›´æ¥ä»å­—å…¸è·å–æ•°æ®ï¼Œé¿å…æ¨¡å‹è½¬æ¢é—®é¢˜
                value_tuple = (
                    data.get('ts_code'),
                    data.get('stock_code') or data.get('code'),
                    data.get('stock_name') or data.get('name'),
                    data.get('trade_date') or data.get('date'),
                    data.get('open'),
                    data.get('high'),
                    data.get('low'),
                    data.get('close'),
                    data.get('preclose'),
                    data.get('volume'),
                    data.get('amount'),
                    data.get('trade_status', 1),
                    data.get('is_st', False),
                    data.get('adjust_flag', 3),
                    data.get('change_rate') or data.get('pct_chg'),
                    data.get('turnover_rate') or data.get('turn')
                )

                # è°ƒè¯•ï¼šæ£€æŸ¥æ•°å€¼å­—æ®µæ˜¯å¦è¶…å‡ºæ•°æ®åº“ç²¾åº¦é™åˆ¶
                change_rate = value_tuple[14]
                turnover_rate = value_tuple[15]

                if change_rate is not None and abs(change_rate) >= 10000:
                    print(f"âš ï¸  change_rate è¶…å‡ºç²¾åº¦é™åˆ¶: {change_rate}")
                if turnover_rate is not None and abs(turnover_rate) >= 10000:
                    print(f"âš ï¸  turnover_rate è¶…å‡ºç²¾åº¦é™åˆ¶: {turnover_rate}")

                values.append(value_tuple)

            query = """
                INSERT INTO his_kline_day (
                    ts_code, stock_code, stock_name, trade_date, open, high, low, close,
                    preclose, volume, amount, trade_status, is_st, adjust_flag,
                    change_rate, turnover_rate
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ts_code, trade_date) DO UPDATE SET
                    ts_code = EXCLUDED.ts_code,
                    stock_name = EXCLUDED.stock_name,
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    preclose = EXCLUDED.preclose,
                    volume = EXCLUDED.volume,
                    amount = EXCLUDED.amount,
                    trade_status = EXCLUDED.trade_status,
                    is_st = EXCLUDED.is_st,
                    adjust_flag = EXCLUDED.adjust_flag,
                    change_rate = EXCLUDED.change_rate,
                    turnover_rate = EXCLUDED.turnover_rate,
                    update_time = CURRENT_TIMESTAMP
            """
            self.db_conn.execute_batch(query, values)

    
    def sync_fundamentals_data(self, **options) -> Dict[str, Any]:
        """
        åŒæ­¥åŸºæœ¬é¢æ•°æ® - æ–°å¢æ–¹æ³•

        Args:
            **options: åŒæ­¥é€‰é¡¹
                - batch_size: æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤50
                - dry_run: æ˜¯å¦è¯•è¿è¡Œï¼Œé»˜è®¤False
                - list_status: è‚¡ç¥¨ä¸Šå¸‚çŠ¶æ€è¿‡æ»¤ï¼Œé»˜è®¤'L'ï¼ˆä»…ä¸Šå¸‚ï¼‰

        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        return self.fundamentals_manager.execute_sync(**options)
